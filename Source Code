# -*- coding: utf-8 -*-
"""Machine Leanrning-II Project Work.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uhejpyAi1qTNcK2zCKC0VFXmBSzdi-cd

#**Machine Learining Project -  Dimentionality Redcution for Visualization**
##KMeans - Unsupervised Learning Algorithm used

##Dimentionality Reduction Techniques used are:
*   PCA
*   LDA
*   ICA

##Datasets used are
*   Iris
*   Wine
*   Breast Cancer
*   make_blobs
*   make_moons
*   make_circles

##Metrics used are:
*   shilhouette_score
*   adjusted_rand_score
*   homogeneity_score
*   completeness_score
*   v_meansure_score
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.decomposition import PCA, FastICA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.cluster import KMeans
from sklearn.metrics import (silhouette_score, adjusted_rand_score,
                             homogeneity_score, completeness_score,
                             v_measure_score)

# Function to apply clustering and evaluate performance using multiple metrics
def apply_kmeans_and_evaluate(X_reduced, y_true, n_clusters=3):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(X_reduced)

    # Evaluation Metrics
    silhouette = silhouette_score(X_reduced, clusters)
    ari = adjusted_rand_score(y_true, clusters)
    homogeneity = homogeneity_score(y_true, clusters)
    completeness = completeness_score(y_true, clusters)
    v_measure = v_measure_score(y_true, clusters)

    return {
        'Silhouette Score': silhouette,
        'Adjusted Rand Index': ari,
        'Homogeneity Score': homogeneity,
        'Completeness Score': completeness,
        'V-Measure': v_measure
    }

def display_results(df, dataset_name):
    """
    Prints the clustering performance results for a given dataset.

    Parameters:
        df (pd.DataFrame): The DataFrame containing the results.
        dataset_name (str): The name of the dataset.
    """
    print(f"\n\t\t\t\tClustering Performance on {dataset_name} Dataset:\n\n")
    pd.set_option('display.max_columns', None)  # Show all columns
    pd.set_option('display.width', 1000)        # Set the width to a large number to prevent wrapping

    # Print the DataFrame
    print(df.set_index('Method'))

import plotly.graph_objects as go
from plotly.subplots import make_subplots

def plot_dimensionality_reduction(X, X_pca, X_lda, X_ica, y):
    """
    Visualizes the original data and the results of PCA, LDA, and ICA side by side.

    Parameters:
        X (np.ndarray): The original dataset.
        X_pca (np.ndarray): The dataset after applying PCA.
        X_lda (np.ndarray): The dataset after applying LDA.
        X_ica (np.ndarray): The dataset after applying ICA.
        y (np.ndarray): The labels for the dataset.
    """

    # Create subplots for Original Data and PCA
    fig1 = make_subplots(rows=1, cols=2, subplot_titles=("Original", "PCA"))

    # Original Data Scatter
    fig1.add_trace(
        go.Scatter(x=X[:, 0], y=X[:, 1], mode='markers', marker=dict(color=y, colorscale='Viridis', size=10)),
        row=1, col=1
    )

    # PCA Scatter
    fig1.add_trace(
        go.Scatter(x=X_pca[:, 0], y=X_pca[:, 1] if X_pca.shape[1] > 1 else [0]*len(X_pca), mode='markers', marker=dict(color=y, colorscale='Viridis', size=10)),
        row=1, col=2
    )

    # Update layout to remove overall title and set individual subplot titles
    fig1.update_layout(template="plotly_white", width=1000, height=500)
    fig1.update_xaxes(title_text="Original", row=1, col=1)
    fig1.update_xaxes(title_text="PCA", row=1, col=2)

    fig1.show()

    # Create subplots for LDA and ICA
    fig2 = make_subplots(rows=1, cols=2, subplot_titles=("LDA", "ICA"))

    # LDA Scatter
    fig2.add_trace(
        go.Scatter(x=X_lda[:, 0], y=X_lda[:, 1] if X_lda.shape[1] > 1 else [0]*len(X_lda), mode='markers', marker=dict(color=y, colorscale='Viridis', size=10)),
        row=1, col=1
    )

    # ICA Scatter
    fig2.add_trace(
        go.Scatter(x=X_ica[:, 0], y=X_ica[:, 1] if X_ica.shape[1] > 1 else [0]*len(X_ica), mode='markers', marker=dict(color=y, colorscale='Viridis', size=10)),
        row=1, col=2
    )

    # Update layout to remove overall title and set individual subplot titles
    fig2.update_layout(template="plotly_white", width=1000, height=500)
    fig2.update_xaxes(title_text="LDA", row=1, col=1)
    fig2.update_xaxes(title_text="ICA", row=1, col=2)

    fig2.show()

import plotly.express as px
# Function to plot clustering performance metrics
def plot_clustering_performance(results_df, dataset_name):
    """
    Plots the clustering performance metrics for a given dataset.

    Parameters:
        results_df (pd.DataFrame): DataFrame containing the clustering results with 'Method' as a column.
        dataset_name (str): Name of the dataset for the plot title.
    """
    # Reset the index to make 'Method' a regular column if it's currently set as an index
    if results_df.index.name == 'Method':
        results_df = results_df.reset_index()

    # Melt the DataFrame to long format for easier plotting
    results_long = pd.melt(results_df, id_vars=['Method'], var_name='Metric', value_name='Score')

    # Create an interactive bar chart
    fig = px.bar(
        results_long,
        x='Method',
        y='Score',
        color='Metric',
        barmode='group',
        title=f"Clustering Performance on {dataset_name} Dataset with Different Dimensionality Reduction Techniques",
        labels={'Score': 'Metric Score', 'Method': 'Dimensionality Reduction Method'}
    )

    # Customize the layout for better visualization
    fig.update_layout(
        xaxis_title="Dimensionality Reduction Method",
        yaxis_title="Metric Score",
        legend_title="Evaluation Metrics",
        template="plotly_white",
        width=800,
        height=600
    )

    # Display the plot
    fig.show()

# Function to plot a specific metric score across datasets and methods
def plot_metric_score(results_long, metric_name, width=800, height=600):
    # Filter the results for the specified metric
    metric_results = results_long[results_long['Metric'] == metric_name]

    # Create an interactive bar chart for the given metric
    fig = px.bar(
        metric_results,
        x='Method',
        y='Score',
        color='Dataset',
        barmode='group',
        title=f"{metric_name} Across Datasets and Methods",
        labels={'Score': f'{metric_name}', 'Method': 'Dimensionality Reduction Method'}
    )

    # Customize the layout for better visualization
    fig.update_layout(
        xaxis_title="Dimensionality Reduction Method",
        yaxis_title=f"{metric_name}",
        legend_title="Dataset",
        template="plotly_white",
        width=width,
        height=height
    )

    # Show the plot
    fig.show()

# Load the Iris dataset
iris = datasets.load_iris()
X_iris = iris.data  # Features
y_iris = iris.target  # True labels (used only for evaluation, not in clustering)

# List to store results for the Iris dataset
iris_results = []

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
iris_original_results = apply_kmeans_and_evaluate(X_iris, y_iris)
iris_original_results['Method'] = 'Original'
iris_results.append(iris_original_results)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca = PCA(n_components=2)
X_iris_pca = pca.fit_transform(X_iris)
iris_pca_results = apply_kmeans_and_evaluate(X_iris_pca, y_iris)
iris_pca_results['Method'] = 'PCA'
iris_results.append(iris_pca_results)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda = LDA(n_components=2)
X_iris_lda = lda.fit_transform(X_iris, y_iris)
iris_lda_results = apply_kmeans_and_evaluate(X_iris_lda, y_iris)
iris_lda_results['Method'] = 'LDA'
iris_results.append(iris_lda_results)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica = FastICA(n_components=2, random_state=42)
X_iris_ica = ica.fit_transform(X_iris)
iris_ica_results = apply_kmeans_and_evaluate(X_iris_ica, y_iris)
iris_ica_results['Method'] = 'ICA'
iris_results.append(iris_ica_results)

# Convert results list to DataFrame for better visualization
iris_results_df = pd.DataFrame(iris_results)

display_results(iris_results_df, 'Iris')

plot_dimensionality_reduction(X_iris, X_iris_pca, X_iris_lda, X_iris_ica, y_iris)

plot_clustering_performance(iris_results_df, "Iris")

# Load the Wine dataset
wine_dataset = datasets.load_wine()
X_wine = wine_dataset.data  # Features
y_wine = wine_dataset.target  # True labels (used only for evaluation, not in clustering)

# List to store results
wine_results = []

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
wine_original_results = apply_kmeans_and_evaluate(X_wine, y_wine)
wine_original_results['Method'] = 'Original'
wine_results.append(wine_original_results)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca_wine = PCA(n_components=2)
X_pca_wine = pca_wine.fit_transform(X_wine)
wine_pca_results = apply_kmeans_and_evaluate(X_pca_wine, y_wine)
wine_pca_results['Method'] = 'PCA'
wine_results.append(wine_pca_results)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda_wine = LDA(n_components=2)
X_lda_wine = lda_wine.fit_transform(X_wine, y_wine)
wine_lda_results = apply_kmeans_and_evaluate(X_lda_wine, y_wine)
wine_lda_results['Method'] = 'LDA'
wine_results.append(wine_lda_results)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica_wine = FastICA(n_components=2, random_state=42)
X_ica_wine = ica_wine.fit_transform(X_wine)
wine_ica_results = apply_kmeans_and_evaluate(X_ica_wine, y_wine)
wine_ica_results['Method'] = 'ICA'
wine_results.append(wine_ica_results)

# Convert results list to DataFrame for better visualization
wine_results_df = pd.DataFrame(wine_results)

display_results(wine_results_df, 'Wine')

plot_dimensionality_reduction(X_wine, X_pca_wine, X_lda_wine, X_ica_wine, y_wine)

plot_clustering_performance(wine_results_df, "Wine")

# Load the Breast Cancer dataset
bc_data = datasets.load_breast_cancer()
X_bc = bc_data.data  # Features
y_bc = bc_data.target  # True labels (used only for evaluation, not in clustering)

# List to store results
results_bc = []  # Unique variable name for results

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
original_results_bc = apply_kmeans_and_evaluate(X_bc, y_bc)
original_results_bc['Method'] = 'Original'
results_bc.append(original_results_bc)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca_bc = PCA(n_components=2)
X_pca_bc = pca_bc.fit_transform(X_bc)
pca_results_bc = apply_kmeans_and_evaluate(X_pca_bc, y_bc)
pca_results_bc['Method'] = 'PCA'
results_bc.append(pca_results_bc)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda_bc = LDA(n_components=1)  # LDA can have at most (n_classes - 1) components
X_lda_bc = lda_bc.fit_transform(X_bc, y_bc)
lda_results_bc = apply_kmeans_and_evaluate(X_lda_bc, y_bc)
lda_results_bc['Method'] = 'LDA'
results_bc.append(lda_results_bc)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica_bc = FastICA(n_components=2, random_state=42)
X_ica_bc = ica_bc.fit_transform(X_bc)
ica_results_bc = apply_kmeans_and_evaluate(X_ica_bc, y_bc)
ica_results_bc['Method'] = 'ICA'
results_bc.append(ica_results_bc)

# Convert results list to DataFrame for better visualization
results_df_bc = pd.DataFrame(results_bc)

display_results(results_df_bc, 'Breast Cancer')

plot_dimensionality_reduction(X_bc, X_pca_bc, X_lda_bc, X_ica_bc, y_bc)

plot_clustering_performance(results_df_bc, "Breast Cancer")

from sklearn.datasets import make_blobs

# Generate synthetic dataset using make_blobs
X, y = make_blobs(n_samples=1000, centers=5, n_features=10, random_state=42)

# List to store results
results_blob = []

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
original_results = apply_kmeans_and_evaluate(X, y)
original_results['Method'] = 'Original'
results_blob.append(original_results)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
pca_results = apply_kmeans_and_evaluate(X_pca, y)
pca_results['Method'] = 'PCA'
results_blob.append(pca_results)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda = LDA(n_components=2)
X_lda = lda.fit_transform(X, y)
lda_results = apply_kmeans_and_evaluate(X_lda, y)
lda_results['Method'] = 'LDA'
results_blob.append(lda_results)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica = FastICA(n_components=2, random_state=42)
X_ica = ica.fit_transform(X)
ica_results = apply_kmeans_and_evaluate(X_ica, y)
ica_results['Method'] = 'ICA'
results_blob.append(ica_results)

# Convert results list to DataFrame for better visualization
results_df_blob = pd.DataFrame(results_blob)

display_results(results_df_blob, 'Make Blobs')

plot_dimensionality_reduction(X, X_pca, X_lda, X_ica, y)

plot_clustering_performance(results_df_blob, "Make Blobs")

from sklearn.datasets import make_moons

# Generate synthetic dataset using make_moons
X_moon, y_moon = make_moons(n_samples=1000, noise=0.1, random_state=42)

# List to store results
results_moon = []

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
original_results = apply_kmeans_and_evaluate(X_moon, y_moon)
original_results['Method'] = 'Original'
results_moon.append(original_results)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca = PCA(n_components=2)
X_pca_moon = pca.fit_transform(X_moon)
pca_results = apply_kmeans_and_evaluate(X_pca_moon, y_moon)
pca_results['Method'] = 'PCA'
results_moon.append(pca_results)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda = LDA(n_components=1)  # LDA requires 1 less than the number of classes
X_lda_moon = lda.fit_transform(X_moon, y_moon)
lda_results = apply_kmeans_and_evaluate(X_lda_moon, y_moon)
lda_results['Method'] = 'LDA'
results_moon.append(lda_results)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica = FastICA(n_components=2, random_state=42)
X_ica_moon = ica.fit_transform(X_moon)
ica_results = apply_kmeans_and_evaluate(X_ica_moon, y_moon)
ica_results['Method'] = 'ICA'
results_moon.append(ica_results)

# Convert results list to DataFrame for better visualization
results_df_moon = pd.DataFrame(results_moon)

display_results(results_df_moon, 'Make Moons')

plot_dimensionality_reduction(X_moon, X_pca_moon, X_lda_moon, X_ica_moon, y_moon)

plot_clustering_performance(results_df_moon, "Make Moons")

from sklearn.datasets import make_circles
# Generate synthetic dataset using make_circles
X_c, y_c = make_circles(n_samples=1000, noise=0.1, factor=0.5, random_state=42)

# List to store results
results_c = []

# 1. Original Data Clustering (without dimensionality reduction)
print("Original Data Clustering:")
original_results = apply_kmeans_and_evaluate(X_c, y_c)
original_results['Method'] = 'Original'
results_c.append(original_results)

# 2. PCA Dimensionality Reduction
print("PCA Dimensionality Reduction:")
pca = PCA(n_components=2)
X_pca_c = pca.fit_transform(X_c)
pca_results = apply_kmeans_and_evaluate(X_pca, y_c)
pca_results['Method'] = 'PCA'
results_c.append(pca_results)

# 3. LDA Dimensionality Reduction
print("LDA Dimensionality Reduction:")
lda = LDA(n_components=1)  # LDA requires 1 less than the number of classes
X_lda_c = lda.fit_transform(X_c, y_c)
lda_results = apply_kmeans_and_evaluate(X_lda, y_c)
lda_results['Method'] = 'LDA'
results_c.append(lda_results)

# 4. ICA Dimensionality Reduction
print("ICA Dimensionality Reduction:")
ica = FastICA(n_components=2, random_state=42)
X_ica_c = ica.fit_transform(X_c)
ica_results = apply_kmeans_and_evaluate(X_ica, y_c)
ica_results['Method'] = 'ICA'
results_c.append(ica_results)

# Convert results list to DataFrame for better visualization
results_df_c = pd.DataFrame(results_c)

display_results(results_df_c, 'Make Circles')

plot_dimensionality_reduction(X_c, X_pca_c, X_lda_c, X_ica_c, y_c)

plot_clustering_performance(results_df_c, "Make Circles")

import pandas as pd

# Assuming you have results from all datasets
results_list = [
    iris_results_df.assign(Dataset='Iris'),
    wine_results_df.assign(Dataset='Wine'),
    results_df_bc.assign(Dataset='Breast Cancer'),
    results_df_blob.assign(Dataset='Make Blobs'),
    results_df_moon.assign(Dataset='Moon'),
    results_df_c.assign(Dataset='Circles')
]

# Concatenate all results into a single DataFrame
all_results_df = pd.concat(results_list, ignore_index=True)

# Set a multi-index for better organization
all_results_df.set_index(['Dataset', 'Method'], inplace=True)

# Display the results
print("\n\t\t\t\tClustering Performance Summary:\n")
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.width', 1000)        # Prevent wrapping

# Print the DataFrame
print(all_results_df)

# Optionally, you can use descriptive statistics for better understanding
summary_stats = all_results_df.groupby('Dataset').describe()
print("\n\t\t\t\tSummary Statistics for Each Dataset:\n")
print(summary_stats)

import plotly.express as px

# Assume `all_results_df` is your combined DataFrame from the previous step

# Melt the DataFrame to long format for easier plotting
results_long = all_results_df.reset_index().melt(id_vars=['Dataset', 'Method'],
                                                    var_name='Metric',
                                                    value_name='Score')

# Create an interactive bar chart
fig = px.bar(
    results_long,
    x='Method',
    y='Score',
    color='Metric',
    barmode='group',
    facet_col='Dataset',
    title="Clustering Performance Metrics Across Datasets and Methods",
    labels={'Score': 'Metric Score', 'Method': 'DR Method'}
)

# Customize the layout for better visualization
fig.update_layout(
    xaxis_title="DR Method",
    yaxis_title="Metric Score",
    legend_title="Evaluation Metrics",
    template="plotly_white",
    width=1425,
    height=800
)

# Display the plot
fig.show()

plot_metric_score(results_long, 'Silhouette Score')

plot_metric_score(results_long, 'Adjusted Rand Index')

plot_metric_score(results_long, 'Homogeneity Score')

plot_metric_score(results_long, 'Completeness Score')

# Example for plotting only V-Measure
v_measure_results = results_long[results_long['Metric'] == 'V-Measure']

fig_v_measure = px.bar(
    v_measure_results,
    x='Method',
    y='Score',
    color='Dataset',
    barmode='group',
    title="V-Measure Across Datasets and Methods",
    labels={'Score': 'V-Measure', 'Method': 'Dimensionality Reduction Method'}
)

fig_v_measure.update_layout(
    xaxis_title="Dimensionality Reduction Method",
    yaxis_title="V-Measure",
    legend_title="Dataset",
    template="plotly_white",
    width=800,
    height=600
)

fig_v_measure.show()

from google.colab import files

  # Save the DataFrame as an Excel file in the Colab environment
  output_filename = "metrics_scores.xlsx"
  all_results_df.to_excel(output_filename, index=False)

  # Download the file to your local machine
  files.download(output_filename)

  print(f"Metrics scores have been saved and downloaded as: {output_filename}")
